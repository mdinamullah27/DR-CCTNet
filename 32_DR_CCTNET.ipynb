{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmNQzh3KMCRh",
        "outputId": "da2a58c5-2e18-4339-c149-fb5f275057dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sun Feb 12 12:03:56 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 516.94       Driver Version: 516.94       CUDA Version: 11.7     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0  On |                  N/A |\n",
            "|  0%   47C    P8     3W /  75W |    936MiB /  4096MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|    0   N/A  N/A      1308    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
            "|    0   N/A  N/A      2376    C+G   ...bbwe\\Microsoft.Photos.exe    N/A      |\n",
            "|    0   N/A  N/A      3096    C+G   ...root\\Office16\\WINWORD.EXE    N/A      |\n",
            "|    0   N/A  N/A      4900    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
            "|    0   N/A  N/A      5944    C+G   ...me\\Application\\chrome.exe    N/A      |\n",
            "|    0   N/A  N/A      7204    C+G   ...gram Desktop\\Telegram.exe    N/A      |\n",
            "|    0   N/A  N/A      7616    C+G   ...artMenuExperienceHost.exe    N/A      |\n",
            "|    0   N/A  N/A      8328    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
            "|    0   N/A  N/A      9520    C+G   ...lPanel\\SystemSettings.exe    N/A      |\n",
            "|    0   N/A  N/A     12640    C+G   ...2txyewy\\TextInputHost.exe    N/A      |\n",
            "|    0   N/A  N/A     12964    C+G   ...oft OneDrive\\OneDrive.exe    N/A      |\n",
            "|    0   N/A  N/A     13228    C+G   ...3d8bbwe\\CalculatorApp.exe    N/A      |\n",
            "|    0   N/A  N/A     13652    C+G   ...8wekyb3d8bbwe\\Cortana.exe    N/A      |\n",
            "|    0   N/A  N/A     14056    C+G   ...qxf38zg5c\\Skype\\Skype.exe    N/A      |\n",
            "|    0   N/A  N/A     14156    C+G   ...ck\\app-4.29.149\\slack.exe    N/A      |\n",
            "|    0   N/A  N/A     14776    C+G   ...qxf38zg5c\\Skype\\Skype.exe    N/A      |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TRm9ppk4ip2",
        "outputId": "b68d2bcc-abee-4a83-cae2-38c5883b8798"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your runtime has 17.1 gigabytes of available RAM\n",
            "\n",
            "Not using a high-RAM runtime\n"
          ]
        }
      ],
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uPWdyLkkpbgg"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTQutar1pjNs"
      },
      "outputs": [],
      "source": [
        "labels = [\"0\",\"1\",\"2\",\"3\",\"4\"]\n",
        "img_size = 32          #change it on 32, 28, 16, 24\n",
        "def get_data(data_dir):\n",
        "    data = []\n",
        "    for label in labels:\n",
        "        path = os.path.join(data_dir, label)\n",
        "        class_num = labels.index(label)\n",
        "        for img in os.listdir(path):\n",
        "            try:\n",
        "                img_arr = cv2.imread(os.path.join(path, img))[...,::-1] #convert BGR to RGB format\n",
        "                resized_arr = cv2.resize(img_arr, (img_size, img_size)) # Reshaping images to preferred size\n",
        "                data.append([resized_arr, class_num])\n",
        "            except Exception as e:\n",
        "                print(e)\n",
        "    return np.array(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iNqiQRtpk89",
        "outputId": "5c57bcf3-a235-45d4-8086-13a5e25a16b4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3820\\3925706549.py:15: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  return np.array(data)\n"
          ]
        }
      ],
      "source": [
        "train = get_data(r\"H:\\Inam\\New folder\\aug marge\\aug marge\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A2o0PW3-p8kT",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# l = []\n",
        "# for i in train:\n",
        "#     if(i[1] == 0):\n",
        "#         l.append(\"0\")\n",
        "#     elif(i[1] == 1):\n",
        "#           l.append(\"1\")\n",
        "#     elif(i[1] == 2):\n",
        "#           l.append(\"2\")\n",
        "#     elif(i[1] == 3):\n",
        "#           l.append(\"3\")\n",
        "#     elif(i[1] == 4):\n",
        "#           l.append(\"4\")\n",
        "\n",
        "\n",
        "# sns.set_style('darkgrid')\n",
        "# sns.countplot(l)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uqw12vpiqABT",
        "outputId": "d11d1a5e-8211-4202-c1c1-f002ebe492a2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, '0')"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize = (5,5))\n",
        "plt.imshow(train[1][0])\n",
        "plt.title(labels[train[0][1]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4461DWCoqCPI"
      },
      "outputs": [],
      "source": [
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "\n",
        "for feature, label in train:\n",
        "  x_train.append(feature)\n",
        "  y_train.append(label)\n",
        "x_train = np.array(x_train) / 255\n",
        "x_train.reshape(-1, img_size, img_size, 1)\n",
        "y_train = np.array(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZdl1A3TqFQL"
      },
      "outputs": [],
      "source": [
        "# split with a stratified sampling\n",
        "from sklearn.model_selection import train_test_split\n",
        "(x_train, x_test, y_train, y_test) = train_test_split(x_train, y_train,\n",
        "    test_size=0.15, stratify=y_train, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kkTBOgrdqNi7"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q tensorflow-addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8iI1ToY4qPgO"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_addons as tfa\n",
        "import tensorflow as tf\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9X65w08360ze"
      },
      "outputs": [],
      "source": [
        "y_train = keras.utils.to_categorical(\n",
        "    y_train, num_classes=5, dtype='float32'\n",
        ")\n",
        "y_test = keras.utils.to_categorical(\n",
        "    y_test, num_classes=5, dtype='float32'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0JRCI5n0qRYz"
      },
      "outputs": [],
      "source": [
        "positional_emb = True\n",
        "conv_layers = 2\n",
        "projection_dim = 128\n",
        "\n",
        "num_heads = 2\n",
        "transformer_units = [\n",
        "    projection_dim\n",
        "]\n",
        "transformer_layers = 1\n",
        "stochastic_depth_rate = 0.1\n",
        "\n",
        "learning_rate = 0.001\n",
        "weight_decay = 0.0001\n",
        "batch_size = 128\n",
        "num_epochs = 400\n",
        "image_size = 32            #change"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTJIIAbjqTcc"
      },
      "outputs": [],
      "source": [
        "num_classes = 5\n",
        "input_shape = (32, 32, 3)           #change\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFxMSXZebuFe",
        "outputId": "503fe7f1-da8f-4666-8043-7382685c0ad2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x_train shape: (215217, 32, 32, 3) - y_train shape: (215217, 5)\n",
            "x_test shape: (37980, 32, 32, 3) - y_test shape: (37980, 5)\n"
          ]
        }
      ],
      "source": [
        "print(f\"x_train shape: {x_train.shape} - y_train shape: {y_train.shape}\")\n",
        "print(f\"x_test shape: {x_test.shape} - y_test shape: {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AcB000FOqamH"
      },
      "outputs": [],
      "source": [
        "class CCTTokenizer(layers.Layer):\n",
        "    def __init__(\n",
        "        self,\n",
        "        kernel_size=3,\n",
        "        stride=1,\n",
        "        padding=1,\n",
        "        pooling_kernel_size=1,\n",
        "        pooling_stride=2,\n",
        "        num_conv_layers=conv_layers,\n",
        "        num_output_channels=[64, 128],\n",
        "        positional_emb=positional_emb,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        super(CCTTokenizer, self).__init__(**kwargs)\n",
        "\n",
        "        # This is our tokenizer.\n",
        "        self.conv_model = keras.Sequential()\n",
        "        for i in range(num_conv_layers):\n",
        "            self.conv_model.add(\n",
        "                layers.Conv2D(\n",
        "                    num_output_channels[i],\n",
        "                    kernel_size,\n",
        "                    stride,\n",
        "                    padding=\"valid\",\n",
        "                    use_bias=False,\n",
        "                    activation=\"relu\",\n",
        "                    kernel_initializer=\"he_normal\",\n",
        "                )\n",
        "            )\n",
        "            self.conv_model.add(layers.ZeroPadding2D(padding))\n",
        "            self.conv_model.add(\n",
        "                layers.MaxPool2D(pooling_kernel_size, pooling_stride, \"same\")\n",
        "            )\n",
        "\n",
        "        self.positional_emb = positional_emb\n",
        "\n",
        "    def call(self, images):\n",
        "        outputs = self.conv_model(images)\n",
        "        # After passing the images through our mini-network the spatial dimensions\n",
        "        # are flattened to form sequences.\n",
        "        reshaped = tf.reshape(\n",
        "            outputs,\n",
        "            (-1, tf.shape(outputs)[1] * tf.shape(outputs)[2], tf.shape(outputs)[-1]),\n",
        "        )\n",
        "        return reshaped\n",
        "\n",
        "    def positional_embedding(self, image_size):\n",
        "        # Positional embeddings are optional in CCT. Here, we calculate\n",
        "        # the number of sequences and initialize an `Embedding` layer to\n",
        "        # compute the positional embeddings later.\n",
        "        if self.positional_emb:\n",
        "            dummy_inputs = tf.ones((1, image_size, image_size, 3))\n",
        "            dummy_outputs = self.call(dummy_inputs)\n",
        "            sequence_length = tf.shape(dummy_outputs)[1]\n",
        "            projection_dim = tf.shape(dummy_outputs)[-1]\n",
        "\n",
        "            embed_layer = layers.Embedding(\n",
        "                input_dim=sequence_length, output_dim=projection_dim\n",
        "            )\n",
        "            return embed_layer, sequence_length\n",
        "        else:\n",
        "            return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PFLyTlEEqhwv"
      },
      "outputs": [],
      "source": [
        "# Referred from: github.com:rwightman/pytorch-image-models.\n",
        "class StochasticDepth(layers.Layer):\n",
        "    def __init__(self, drop_prop, **kwargs):\n",
        "        super(StochasticDepth, self).__init__(**kwargs)\n",
        "        self.drop_prob = drop_prop\n",
        "\n",
        "    def call(self, x, training=None):\n",
        "        if training:\n",
        "            keep_prob = 1 - self.drop_prob\n",
        "            shape = (tf.shape(x)[0],) + (1,) * (len(tf.shape(x)) - 1)\n",
        "            random_tensor = keep_prob + tf.random.uniform(shape, 0, 1)\n",
        "            random_tensor = tf.floor(random_tensor)\n",
        "            return (x / keep_prob) * random_tensor\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0r8TOIiyqjyt"
      },
      "outputs": [],
      "source": [
        "def mlp(x, hidden_units, dropout_rate):\n",
        "    for units in hidden_units:\n",
        "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
        "        x = layers.Dropout(dropout_rate)(x)\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFWfh2-0ql_u"
      },
      "outputs": [],
      "source": [
        "# Note the rescaling layer. These layers have pre-defined inference behavior.\n",
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.Rescaling(scale=1.0 / 255),\n",
        "        layers.RandomCrop(image_size, image_size),\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "    ],\n",
        "    name=\"data_augmentation\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5I0BDxrkqpFG"
      },
      "outputs": [],
      "source": [
        "def create_cct_model(\n",
        "    image_size=image_size,\n",
        "    input_shape=input_shape,\n",
        "    num_heads=num_heads,\n",
        "    projection_dim=projection_dim,\n",
        "    transformer_units=transformer_units,\n",
        "):\n",
        "\n",
        "    inputs = layers.Input(input_shape)\n",
        "\n",
        "    # Augment data.\n",
        "    augmented = data_augmentation(inputs)\n",
        "\n",
        "    # Encode patches.\n",
        "    cct_tokenizer = CCTTokenizer()\n",
        "    encoded_patches = cct_tokenizer(augmented)\n",
        "\n",
        "    # Apply positional embedding.\n",
        "    if positional_emb:\n",
        "        pos_embed, seq_length = cct_tokenizer.positional_embedding(image_size)\n",
        "        positions = tf.range(start=0, limit=seq_length, delta=1)\n",
        "        position_embeddings = pos_embed(positions)\n",
        "        encoded_patches += position_embeddings\n",
        "\n",
        "    # Calculate Stochastic Depth probabilities.\n",
        "    dpr = [x for x in np.linspace(0, stochastic_depth_rate, transformer_layers)]\n",
        "\n",
        "    # Create multiple layers of the Transformer block.\n",
        "    for i in range(transformer_layers):\n",
        "        # Layer normalization 1.\n",
        "        x1 = layers.LayerNormalization(epsilon=1e-5)(encoded_patches)\n",
        "\n",
        "        # Create a multi-head attention layer.\n",
        "        attention_output = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
        "        )(x1, x1)\n",
        "\n",
        "        # Skip connection 1.\n",
        "        attention_output = StochasticDepth(dpr[i])(attention_output)\n",
        "        x2 = layers.Add()([attention_output, encoded_patches])\n",
        "\n",
        "        # Layer normalization 2.\n",
        "        x3 = layers.LayerNormalization(epsilon=1e-5)(x2)\n",
        "\n",
        "        # MLP.\n",
        "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
        "\n",
        "        # Skip connection 2.\n",
        "        x3 = StochasticDepth(dpr[i])(x3)\n",
        "        encoded_patches = layers.Add()([x3, x2])\n",
        "\n",
        "    # Apply sequence pooling.\n",
        "    representation = layers.LayerNormalization(epsilon=1e-5)(encoded_patches)\n",
        "    attention_weights = tf.nn.softmax(layers.Dense(1)(representation), axis=1)\n",
        "    weighted_representation = tf.matmul(\n",
        "        attention_weights, representation, transpose_a=True\n",
        "    )\n",
        "    weighted_representation = tf.squeeze(weighted_representation, -2)\n",
        "\n",
        "    # Classify outputs.\n",
        "    logits = layers.Dense(num_classes)(weighted_representation)\n",
        "    # Create the Keras model.\n",
        "    model = keras.Model(inputs=inputs, outputs=logits)\n",
        "    model.summary()\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1uHRg1SSheT8",
        "outputId": "7517bc65-63b0-4dcf-81f4-9eccd6c9145f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " data_augmentation (Sequential)  (None, 32, 32, 3)   0           ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " cct_tokenizer (CCTTokenizer)   (None, 64, 128)      75456       ['data_augmentation[0][0]']      \n",
            "                                                                                                  \n",
            " tf.__operators__.add (TFOpLamb  (None, 64, 128)     0           ['cct_tokenizer[0][0]']          \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " layer_normalization (LayerNorm  (None, 64, 128)     256         ['tf.__operators__.add[0][0]']   \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " multi_head_attention (MultiHea  (None, 64, 128)     131968      ['layer_normalization[0][0]',    \n",
            " dAttention)                                                      'layer_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " stochastic_depth (StochasticDe  (None, 64, 128)     0           ['multi_head_attention[0][0]']   \n",
            " pth)                                                                                             \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 64, 128)      0           ['stochastic_depth[0][0]',       \n",
            "                                                                  'tf.__operators__.add[0][0]']   \n",
            "                                                                                                  \n",
            " layer_normalization_1 (LayerNo  (None, 64, 128)     256         ['add[0][0]']                    \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 64, 128)      16512       ['layer_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 64, 128)      0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " stochastic_depth_1 (Stochastic  (None, 64, 128)     0           ['dropout[0][0]']                \n",
            " Depth)                                                                                           \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 64, 128)      0           ['stochastic_depth_1[0][0]',     \n",
            "                                                                  'add[0][0]']                    \n",
            "                                                                                                  \n",
            " layer_normalization_2 (LayerNo  (None, 64, 128)     256         ['add_1[0][0]']                  \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 64, 1)        129         ['layer_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " tf.nn.softmax (TFOpLambda)     (None, 64, 1)        0           ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " tf.linalg.matmul (TFOpLambda)  (None, 1, 128)       0           ['tf.nn.softmax[0][0]',          \n",
            "                                                                  'layer_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " tf.compat.v1.squeeze (TFOpLamb  (None, 128)         0           ['tf.linalg.matmul[0][0]']       \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 5)            645         ['tf.compat.v1.squeeze[0][0]']   \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 225,478\n",
            "Trainable params: 225,478\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/400\n",
            "1514/1514 [==============================] - 628s 388ms/step - loss: 1.3373 - accuracy: 0.5195 - top-5-accuracy: 1.0000 - val_loss: 1.3135 - val_accuracy: 0.5527 - val_top-5-accuracy: 1.0000\n",
            "Epoch 2/400\n",
            "1514/1514 [==============================] - 581s 384ms/step - loss: 1.2284 - accuracy: 0.5890 - top-5-accuracy: 1.0000 - val_loss: 1.2013 - val_accuracy: 0.6020 - val_top-5-accuracy: 1.0000\n",
            "Epoch 3/400\n",
            "1514/1514 [==============================] - 582s 385ms/step - loss: 1.1949 - accuracy: 0.6028 - top-5-accuracy: 1.0000 - val_loss: 1.1721 - val_accuracy: 0.6145 - val_top-5-accuracy: 1.0000\n",
            "Epoch 4/400\n",
            "1514/1514 [==============================] - 581s 384ms/step - loss: 1.1738 - accuracy: 0.6131 - top-5-accuracy: 1.0000 - val_loss: 1.2011 - val_accuracy: 0.6085 - val_top-5-accuracy: 1.0000\n",
            "Epoch 5/400\n",
            "1514/1514 [==============================] - 584s 386ms/step - loss: 1.1577 - accuracy: 0.6190 - top-5-accuracy: 1.0000 - val_loss: 1.1565 - val_accuracy: 0.6209 - val_top-5-accuracy: 1.0000\n",
            "Epoch 6/400\n",
            " 815/1514 [===============>..............] - ETA: 4:20 - loss: 1.1479 - accuracy: 0.6229 - top-5-accuracy: 1.0000"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Input \u001b[1;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 69>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m history\n\u001b[0;32m     68\u001b[0m cct_model \u001b[38;5;241m=\u001b[39m create_cct_model()\n\u001b[1;32m---> 69\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcct_model\u001b[49m\u001b[43m)\u001b[49m\n",
            "Input \u001b[1;32mIn [21]\u001b[0m, in \u001b[0;36mrun_experiment\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m     22\u001b[0m checkpoint_filepath \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mInam\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mcctmodel2 16.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     23\u001b[0m checkpoint_callback \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mModelCheckpoint(\n\u001b[0;32m     24\u001b[0m     checkpoint_filepath,\n\u001b[0;32m     25\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     26\u001b[0m     save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     27\u001b[0m     save_weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     28\u001b[0m )\n\u001b[1;32m---> 30\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m model\u001b[38;5;241m.\u001b[39mload_weights(checkpoint_filepath)\n\u001b[0;32m     40\u001b[0m _, accuracy, top_5_accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(x_test, y_test)\n",
            "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1410\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
            "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
            "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
            "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
            "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
            "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "def run_experiment(model):\n",
        "    optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate=0.001,\n",
        "    beta_1=0.9,\n",
        "    beta_2=0.999,\n",
        "    epsilon=1e-07,\n",
        "    amsgrad=False,\n",
        "    name=\"Adam\"\n",
        ")\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=keras.losses.CategoricalCrossentropy(\n",
        "            from_logits=True, label_smoothing=0.1\n",
        "        ),\n",
        "        metrics=[\n",
        "            keras.metrics.CategoricalAccuracy(name=\"accuracy\"),\n",
        "            keras.metrics.TopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    checkpoint_filepath = r\"H:\\Inam\\Model\\cctmodel2 16.h5\"\n",
        "    checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "        checkpoint_filepath,\n",
        "        monitor=\"val_accuracy\",\n",
        "        save_best_only=True,\n",
        "        save_weights_only=True,\n",
        "    )\n",
        "\n",
        "    history = model.fit(\n",
        "        x=x_train,\n",
        "        y=y_train,\n",
        "        batch_size=batch_size,\n",
        "        epochs=num_epochs,\n",
        "        validation_split=0.10,\n",
        "        callbacks=[checkpoint_callback],\n",
        "    )\n",
        "\n",
        "    model.load_weights(checkpoint_filepath)\n",
        "    _, accuracy, top_5_accuracy = model.evaluate(x_test, y_test)\n",
        "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
        "    print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n",
        "    from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "\n",
        "\n",
        "    # as I've trained my model on MNIST as odd or even (binary classes)\n",
        "    target_names = [\"0\", \"1\", \"2\",\"3\",\"4\"]\n",
        "\n",
        "\n",
        "    # get predict prob and label\n",
        "    ypred = model.predict(x_test, verbose=1)\n",
        "    ypred = np.argmax(ypred, axis=1)\n",
        "    print(classification_report(np.argmax(y_test, axis=1), ypred, target_names=target_names))\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "    import pandas as pd\n",
        "\n",
        "    cm = confusion_matrix(np.argmax(y_test, axis=1), ypred)\n",
        "    cm = pd.DataFrame(cm, range(5),range(5))\n",
        "    plt.figure(figsize = (10,10))\n",
        "\n",
        "    sns.heatmap(cm, annot=True, annot_kws={\"size\": 12}) # font size\n",
        "    plt.show()\n",
        "    return history\n",
        "\n",
        "\n",
        "cct_model = create_cct_model()\n",
        "history = run_experiment(cct_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Rsd1klXSP1HZ"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Train and Validation Losses Over Epochs\", fontsize=14)\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Vk57M4ErS1kt"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history[\"accuracy\"], label=\"train_accuracy\")\n",
        "plt.plot(history.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.title(\"Train and Validation accuracy Over Epochs\", fontsize=14)\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OrC4U9WoS1ku"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P1fbBymJS1ku"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuClass": "premium"
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}